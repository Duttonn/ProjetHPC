# Optimisation HPC - DÃ©tection de Mouvement
## Projet Motion - Du SÃ©quentiel au ParallÃ¨le

**Auteurs:** Nicolas Dutton, Antoine
**Cours:** High Performance Computing - EI5-SE
**Date:** Janvier 2026

---

# Plan de la PrÃ©sentation

1. **Architecture de Test**
2. **Contexte et Objectifs**
3. **Simplification Algorithmique**
4. **Validation Bit-Ã -Bit**
5. **Vectorisation SIMD**
6. **Fusion d'OpÃ©rateurs**
7. **Morphologie SÃ©parable**
8. **ParallÃ©lisation OpenMP**
9. **RÃ©sultats Globaux**
10. **Discussion et Analyse**
11. **Conclusion**

---

# 1. Architecture de Test - Cluster Dalek

## Processeur: AMD Ryzen 9 7945HX

### SpÃ©cifications Techniques
- **CÅ“urs:** 16 cÅ“urs physiques / 32 threads logiques
- **FrÃ©quence:** 2.5 GHz base, jusqu'Ã  5.4 GHz boost
- **Architecture:** Zen 4 (5nm)
- **ISA:** x86-64 avec extensions AVX-512

---

## HiÃ©rarchie MÃ©moire

- **Cache L1:** 32 KB instruction + 32 KB donnÃ©es par cÅ“ur
  - Latence: **0.5 ns** (~1-2 cycles)
- **Cache L2:** 1 MB par cÅ“ur
  - Latence: **7 ns** (~15 cycles)
- **Cache L3:** 64 MB partagÃ© entre tous les cÅ“urs
  - Latence: **40 ns** (~100 cycles)
- **RAM:** DDR5-4800 (38 GB/s bande passante)
  - Latence: **~100 ns** (~250 cycles)

---

# 2. Contexte et Objectifs

## DÃ©tection de Mouvement par CamÃ©ra Fixe

### Pipeline de Traitement (3 Ã©tapes)
```
Grayscale Image
     â†“
[1. Sigma-Delta] â†’ DÃ©tection pixels en mouvement
     â†“ (Image binaire 0/1)
[2. Morphologie] â†’ Nettoyage (Opening + Closing)
     â†“ (Image binaire nettoyÃ©e)
[3. CCL + CCA] â†’ Identification des rÃ©gions (RoIs)
     â†“
   Tracking
```

---

# 3. Simplification Algorithmique 

## ProblÃ¨me: Redondance des Calculs

### Graphe Initial (motion2)
```
Frame t-1:  I[t-1] â†’ Î£âˆ† â†’ Morpho â†’ CCL â†’ RoIs[t-1]
                                              â†“
Frame t:    I[t]   â†’ Î£âˆ† â†’ Morpho â†’ CCL â†’ RoIs[t]
                                              â†“
                                         [k-NN Matching]
```

**Observation Critique:**
Ã€ l'itÃ©ration t, on traite **I[t] ET I[t-1]**
Mais I[t-1] a dÃ©jÃ  Ã©tÃ© traitÃ© Ã  l'itÃ©ration t-1 !

---

## Solution: Produce/Memorize Pattern

### Solution: Produce/Memorize Pattern

```
Frame t:    I[t]   â†’ Î£âˆ† â†’ Morpho â†’ CCL â†’ RoIs[t]
                                         â†“ (mÃ©morisÃ©)
Frame t+1:  I[t+1] â†’ Î£âˆ† â†’ Morpho â†’ CCL â†’ RoIs[t+1]
                                         â†“
                    [k-NN Matching avec RoIs[t] mÃ©morisÃ©]
```

---

## Gain de la Simplification

### Pourquoi c'est Plus Rapide?

**Avant (motion2):**
- N frames â†’ 2N passages dans le pipeline (t et t-1)
- Travail: **2N**

**AprÃ¨s (motion):**
- N frames â†’ N passages dans le pipeline
- Travail: **N**

**Gain thÃ©orique: 2Ã— (division par 2 du travail)**

---

# 4. Validation Bit-Ã -Bit

```
motion2 (rÃ©fÃ©rence)          motion (optimisÃ©)
        â”‚                            â”‚
        â–¼                            â–¼
  ./bin/motion2 --log-path     ./bin/motion --log-path
        â”‚                            â”‚
        â–¼                            â–¼
    logs_ref/                    logs_new/
        â”‚                            â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â–¼  â–¼
              diff logs_ref logs_new
                     â”‚
                     â–¼
        RÃ©sultat: VIDE = IDENTIQUE âœ“
```

**Nos optimisations accÃ©lÃ¨rent SANS changer les rÃ©sultats**

---

# 5. Vectorisation SIMD

## Principe: Data-Level Parallelism

### ExÃ©cution Scalaire (1 pixel/cycle)
```
Cycle 1: |  P0  |
Cycle 2: |  P1  |
Cycle 3: |  P2  |
...
Cycle 32:|  P31 |
```
**Temps total: 32 cycles pour 32 pixels**


---

### ExÃ©cution SIMD AVX-512 (32 pixels/cycle)
```
Cycle 1: | P0 | P1 | P2 | ... | P31 |
```
**Temps total: 1 cycle pour 32 pixels**
**Gain thÃ©orique: 32Ã—**

## Code Scalaire vs SIMD

---


## Pourquoi SIMD est Plus Rapide?

### 1. ParallÃ©lisme de DonnÃ©es
- **32 pixels traitÃ©s en parallÃ¨le** dans un seul registre 512 bits
- MÃªme instruction appliquÃ©e Ã  32 donnÃ©es simultanÃ©ment

### 2. Moins d'Instructions ExÃ©cutÃ©es
- Scalaire: 1920 itÃ©rations de boucle
- SIMD: 60 itÃ©rations de boucle
- **RÃ©duction 32Ã— du nombre d'itÃ©rations**

### 3. Meilleure Utilisation du CPU
- UnitÃ©s de calcul SIMD dÃ©diÃ©es (saturÃ©es)
- Pipeline CPU rempli efficacement

---

## RÃ©sultats SIMD

### RÃ©sultats: Latence Sigma-Delta

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Version             â”‚ Latence (ms) â”‚ Speedup â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ motion2 (scalaire)  â”‚     1.20     â”‚  1.0Ã—   â”‚
â”‚ motion (SIMD AVX)   â”‚     0.569    â”‚  2.1Ã—   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Gain rÃ©el: 2.1Ã— (au lieu de 32Ã— thÃ©orique)**

### Pourquoi pas 32Ã—?
- Overhead load/store mÃ©moire
- Latence accÃ¨s RAM (mÃªme avec cache)
- DÃ©pendances de donnÃ©es
---

# 6. Fusion d'OpÃ©rateurs

## ProblÃ¨me: Cache Misses = Latence RAM

### Pipeline SÃ©quentiel (motion2)

```
Ã‰tape 1: Sigma-Delta
  IG (RAM) â”€â”€â†’ [CPU] â”€â”€â†’ IB (RAM Ã©criture)
                              â†“ (100ns latence!)
Ã‰tape 2: Morpho Opening
  IB (RAM lecture) â”€â”€â†’ [CPU] â”€â”€â†’ IB2 (RAM Ã©criture)
                                     â†“ (100ns latence!)
Ã‰tape 3: Morpho Closing
  IB2 (RAM lecture) â”€â”€â†’ [CPU] â”€â”€â†’ IB (RAM Ã©criture)
```

**CoÃ»t: 3 Ã©critures RAM + 2 lectures RAM = 5 Ã— 100ns = 500ns par pixel**

---

## HiÃ©rarchie MÃ©moire - Rappel

### HiÃ©rarchie MÃ©moire - Rappel

```
L1 Cache:  0.5ns   |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| Rapide!
L2 Cache:  7ns     |â–ˆâ–ˆâ–ˆ|
L3 Cache:  40ns    |
RAM:       100ns                                       | Lent!
```

**Ratio: RAM = 200Ã— plus lent que L1 !**

---

## Solution: Fusion en Une Seule Passe

```
IG (RAM) â”€â”€â†’ [Î£âˆ†] â”€â”€â†’ IB (L1 Cache 0.5ns)
                        â†“
                    [Opening] â”€â”€â†’ IB2 (L1 Cache 0.5ns)
                                   â†“
                               [Closing] â”€â”€â†’ IB (RAM Ã©criture)
```

**CoÃ»t: 1 lecture RAM + 1 Ã©criture RAM = 2 Ã— 100ns = 200ns par pixel**

---

## Pourquoi la Fusion AccÃ©lÃ¨re?

- **AccÃ¨s RAM:** 5 â†’ 2 (gain 2.5Ã—)
- **LocalitÃ© temporelle:** donnÃ©es restent en cache L1 entre Ã©tapes
- **Latence:** L1 = 0.5ns vs RAM = 100ns (200Ã— plus rapide)
- **Synergie SIMD:** cache L1 alimente les unitÃ©s vectorielles Ã  pleine vitesse

---

## RÃ©sultats de la Fusion

### RÃ©sultats: Latence FusionnÃ©e

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Version          â”‚ Sigma-Delta â”‚ Morpho  â”‚ Total SD+Morpho  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ motion2 (sÃ©parÃ©) â”‚   1.20 ms   â”‚ 1.70 ms â”‚     2.90 ms      â”‚
â”‚ motion (fusionnÃ©)â”‚   0.569 ms  â”‚ 1.131ms â”‚     1.700 ms     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Gain: 1.7Ã— (2.9ms â†’ 1.7ms)**

---

# 7. Morphologie SÃ©parable
### Morphologie 3Ã—3 Standard (9 comparaisons/pixel)

```
Ã‰rosion 3Ã—3: min de 9 voisins
â”Œâ”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”
â”‚ 1 â”‚ 2 â”‚ 3 â”‚  â†’  result = min(1,2,3,4,5,6,7,8,9)
â”œâ”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¤
â”‚ 4 â”‚ X â”‚ 5 â”‚      9 comparaisons par pixel!
â”œâ”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¤
â”‚ 6 â”‚ 7 â”‚ 8 â”‚
â””â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”˜
```

**Image 1920Ã—1080: 1920 Ã— 1080 Ã— 9 = 18.6M comparaisons**

---

## Morphologie SÃ©parable (6 comparaisons/pixel)
```
DÃ©composition: 3Ã—3 = (1Ã—3) âˆ˜ (3Ã—1).        

Passe 1 - Horizontale 1Ã—3:                  Passe 2 - Verticale 3Ã—1:
â”Œâ”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”
â”‚ A â”‚ X â”‚ B â”‚  â†’  temp = min(A, X, B)
â””â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”˜
   3 comparaisons                                 â”Œâ”€â”€â”€â”
                                                  â”‚ C â”‚
                                                  â”œâ”€â”€â”€â”¤
                                                  â”‚tempâ”‚  â†’  result = min(C, temp, D)
                                                  â”œâ”€â”€â”€â”¤
                                                  â”‚ D â”‚
                                                  â””â”€â”€â”€â”˜
                                                     3 comparaisons   
```
**Total: 6 comparaisons au lieu de 9**
**Image 1920Ã—1080: 1920 Ã— 1080 Ã— 6 = 12.4M comparaisons**

---

## Avantages de la SÃ©parabilitÃ©

### Pourquoi c'est Plus Rapide?

### 1. RÃ©duction du Nombre d'OpÃ©rations
- **9 ops â†’ 6 ops = rÃ©duction 33%**
- Moins de calculs = moins de temps CPU

### 2. Vectorisation Optimale (Passe Horizontale)

**AccÃ¨s contigus = cache-friendly + SIMD-friendly**


---

## RÃ©sultats Morphologie SÃ©parable

### RÃ©sultats: Latence Morphologie.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Version              â”‚ Ops/pixel        â”‚ Latence (ms) â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ motion2 (3Ã—3 direct) â”‚        9         â”‚     1.70     â”‚
â”‚ motion (sÃ©parable)   â”‚        6         â”‚     1.131    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Gain: 1.5Ã— (1.7ms â†’ 1.13ms)**

### Bonus: Combinaison avec Fusion
- Morpho sÃ©parable + Fusion d'opÃ©rateurs
- Passes horizontales restent en cache L1
- **Synergie des optimisations!**

---

# 8. ParallÃ©lisation OpenMP

## Principe: DÃ©composition de Domaine

### Architecture: 16 CÅ“urs Physiques

```
   â”Œâ”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”
   â”‚Core0â”‚Core1â”‚Core2â”‚Core3â”‚Core4â”‚Core5â”‚Core6â”‚Core7â”‚
   â””â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”˜
â”Œâ”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”
â”‚Core8â”‚Core9â”‚Core10â”‚Coer11â”‚Core12â”‚Core13â”‚Core14â”‚Core15â”‚
â””â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”˜
            Ryzen 9 7945HX (16 cÅ“urs)
```

**IdÃ©e:** Distribuer le traitement sur les 16 cÅ“urs

---

## ImplÃ©mentation OpenMP

### ImplÃ©mentation: OpenMP Parallel For

```c
#pragma omp parallel for schedule(static)
for (int i = i0; i <= i1; i++) {
    // Chaque thread traite un sous-ensemble de lignes
    sigma_delta_morpho_fused(..., i, i, ...);
}
```

**Avec 16 threads â†’ chaque thread traite 1080/16 = 67 lignes**

---

## StratÃ©gie de Scheduling

```
Image 1080 lignes, 16 threads:

Thread 0:  lignes 0-67    â”
Thread 1:  lignes 68-135  â”‚ Chunks contigus
Thread 2:  lignes 136-203 â”‚ â†’ Cache locality
...                        â”‚
Thread 15: lignes 1013-1080â”˜
```

**Avantage:** Chaque thread traite des **lignes consÃ©cutives**
- Cache L2 partagÃ© entre threads proches
- Moins de cache conflicts
- PrÃ©dictibilitÃ© (pas de vol de travail)

---

## Pourquoi OpenMP AccÃ©lÃ¨re?

### 1. Exploitation du ParallÃ©lisme MatÃ©riel
- 16 cÅ“urs disponibles
- Calculs indÃ©pendants (lignes sÃ©parÃ©es)

### 2. ScalabilitÃ© ThÃ©orique
- **16 threads:** T/16 secondes = 16x plus rapide

### 3. LocalitÃ© de Cache
- chunks contigus

---

## RÃ©sultats OpenMP Scaling

### Graphe 1: FPS vs Nombre de Threads

<p align="center"><img src="graph_openmp_scaling_fps.png" alt="OpenMP Scaling - FPS" width="72%"></p>

---

### Graphe 2: Speedup vs Nombre de Threads

<p align="center"><img src="graph_openmp_speedup.png" alt="OpenMP Scaling - Speedup" width="72%"></p>

---

### Tableau DÃ©taillÃ©

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Threads â”‚ Avg FPS â”‚ Speedup vs 1t    â”‚ EfficacitÃ© â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚    1    â”‚   181   â”‚      1.00Ã—       â”‚   100%     â”‚
â”‚    2    â”‚   172   â”‚      0.95Ã—       â”‚    48%     â”‚
â”‚    4    â”‚   189   â”‚      1.04Ã—       â”‚    26%     â”‚
â”‚    8    â”‚   206   â”‚      1.14Ã—       â”‚    14%     â”‚
â”‚   16    â”‚   213   â”‚      1.18Ã—       â”‚     7%     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Gain rÃ©el: 1.18Ã— avec 16 threads (au lieu de 16Ã— idÃ©al)**

---

## Pourquoi Scaling Modeste?

### 1. Loi d'Amdahl

```
Speedup = 1 / ((1-P) + P/N)

Avec:
- P = fraction parallÃ©lisable
- N = nombre de threads
- (1-P) = fraction sÃ©quentielle
```

**Notre cas:**
- DÃ©codage vidÃ©o: sÃ©quentiel (buffered mais coÃ»teux)
- CCL: bottleneck (2.34ms, ~42% du temps)
- k-NN matching: sÃ©quentiel
- **Partie parallÃ©lisable estimÃ©e: P â‰ˆ 50%**

**Speedup max thÃ©orique: 1/(0.5) = 2Ã—**

---

## Limites du ParallÃ©lisme

### 2. Memory Bandwidth Bottleneck

```
16 cÅ“urs Ã— 38 GB/s RAM / 16 = 2.4 GB/s par cÅ“ur

Image 1920Ã—1080Ã—3 (RGB) = 6.2 MB
100 FPS â†’ 620 MB/s par cÅ“ur nÃ©cessaire

Avec 16 threads:
16 Ã— 620 MB/s = 9.9 GB/s < 38 GB/s (OK)

MAIS: AccÃ¨s non parfaits (cache misses, false sharing, ...)
â†’ Saturation partielle de la bande passante
```
---

### 3. Overhead OpenMP
- CrÃ©ation/synchronisation threads: ~1-2 Âµs
- BarriÃ¨res implicites (fin de parallel for)
- Cache coherency protocol (MESI)

### 4. Workload Memory-Bound (pas Compute-Bound)
- CPU attend la RAM plus qu'il ne calcule
- Ajouter plus de threads ne rÃ©sout pas le problÃ¨me RAM

---

## Conclusion OpenMP


**Scaling modeste (1.18Ã—) mais:**
- âœ“ Scaling **positif** (pas de dÃ©gradation)
- âœ“ CombinÃ© avec SIMD+Fusion = **2.4Ã— total**

**C'est normal en HPC** Memory-bound workloads ne scalent jamais linÃ©airement.

---

# 9. RÃ©sultats Globaux

## Graphe 1: Performance FPS par Configuration

<p align="center"><img src="graph_fps_comparison.png" alt="Comparaison FPS - Toutes Configurations" width="72%"></p>


---

## Tableau Performances FPS

**Gain final: 2.4Ã— (90 â†’ 213 FPS)**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Configuration           â”‚ Avg FPS â”‚ Speedup â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ motion2 (rÃ©fÃ©rence)     â”‚   ~90   â”‚  1.0Ã—   â”‚
â”‚ motion (1 thread)       â”‚   181   â”‚  2.0Ã—   â”‚
â”‚ motion (2 threads)      â”‚   172   â”‚  1.9Ã—   â”‚
â”‚ motion (4 threads)      â”‚   189   â”‚  2.1Ã—   â”‚
â”‚ motion (8 threads)      â”‚   206   â”‚  2.3Ã—   â”‚
â”‚ motion (16 threads)     â”‚   213   â”‚  2.4Ã—   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## DÃ©composition des Latences

<p align="center"><img src="graph_latencies_comparison.png" alt="Latences par Ã‰tape - motion2 vs motion" width="72%"></p>

---

## Latences EmpilÃ©es (Breakdown Total)

<p align="center"><img src="graph_latency_stacked.png" alt="Latences EmpilÃ©es - DÃ©composition" width="72%"></p>

---

## Comparaison:
- motion2: 1.20ms (Î£âˆ†) + 1.70ms (Morpho) + 4.30ms (CCL) = 8.67ms total
- motion: 0.569ms (Î£âˆ†) + 1.131ms (Morpho) + 2.340ms (CCL) = 5.516ms total

---

## Tableau Latences DÃ©taillÃ©es

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Ã‰tape            â”‚ motion2 â”‚ motion (optimisÃ©)â”‚ Speedup â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Video decoding   â”‚ 0.17 ms â”‚     0.166 ms     â”‚  1.0Ã—   â”‚
â”‚ Sigma-Delta      â”‚ 1.20 ms â”‚     0.569 ms     â”‚  2.1Ã—   â”‚ â† SIMD
â”‚ Morphology       â”‚ 1.70 ms â”‚     1.131 ms     â”‚  1.5Ã—   â”‚ â† SÃ©parable+SIMD
â”‚ CC Labeling      â”‚ 4.30 ms â”‚     2.340 ms     â”‚  1.8Ã—   â”‚
â”‚ CC Analysis      â”‚ 1.30 ms â”‚     1.300 ms     â”‚  1.0Ã—   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ TOTAL            â”‚ 8.67 ms â”‚     5.516 ms     â”‚  1.6Ã—   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Contribution de Chaque Optimisation

```
90 FPS â”€â”€â†’ Task Graph (2.0Ã—) â”€â”€â†’ SIMD+Fusion+SÃ©parable â”€â”€â†’ OpenMP â”€â”€â†’ 213 FPS
(1.0Ã—)                                                                  (2.4Ã—)
```

- **Task Graph:** 2Ã— -- suppression des calculs redondants
- **SIMD:** 2.1Ã— sur Sigma-Delta -- 32 pixels/cycle (AVX-512)
- **Fusion:** 1.7Ã— sur SD+Morpho -- cache L1 au lieu de RAM
- **Morpho SÃ©parable:** 1.5Ã— -- 9 ops â†’ 6 ops par pixel
- **OpenMP:** 1.18Ã— -- 16 cÅ“urs, scaling limitÃ© par Amdahl

---

# 10. Discussion et Analyse

### Ce qui a Bien MarchÃ©

âœ“ **Fusion d'OpÃ©rateurs** - L'optimisation MVP
  - Exploite la hiÃ©rarchie mÃ©moire
  - Cache L1: 200Ã— plus rapide que RAM
  - Combinaison naturelle avec SIMD

âœ“ **SIMD** - Gain significatif
  - AVX-512: 32 pixels/cycle
  - BibliothÃ¨que MIPP: portabilitÃ©
  - Code lisible et maintenable

âœ“ **Task Graph** - Low-hanging fruit
  - Gain immÃ©diat sans complexitÃ©
  - Correctness proof simple

---

## Limites RencontrÃ©es

### 1. Scaling OpenMP Modeste (1.18Ã—)

**Causes IdentifiÃ©es:**

**A) Loi d'Amdahl**
```
Speedup_max = 1 / (S + P/N)

Avec S = 0.5 (50% sÃ©quentiel)
     P = 0.5 (50% parallÃ¨le)
     N = 16 threads

Speedup_max = 1 / (0.5 + 0.5/16) = 1.88Ã—
Speedup_rÃ©el = 1.18Ã—
```
**EfficacitÃ©: 60% du maximum thÃ©orique**

**B) Memory Bandwidth Bottleneck**
- 16 cÅ“urs accÃ¨dent simultanÃ©ment Ã  la RAM
- Saturation partielle de la bande passante

---

## Ã‰cart ThÃ©orique/Pratique

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Optimisationâ”‚ ThÃ©orique â”‚   RÃ©el     â”‚ Ratio     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ SIMD        â”‚    32Ã—    â”‚    2.1Ã—    â”‚   6.5%    â”‚
â”‚ OpenMP      â”‚    16Ã—    â”‚    1.18Ã—   â”‚   7.4%    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Pourquoi cet Ã©cart?**
- **Latence mÃ©moire** (goulot d'Ã©tranglement)
- **Overhead** (load/store, synchronisation)
- **Partie sÃ©quentielle** (Amdahl)

**C'est normal** Les gains thÃ©oriques supposent:
- Calcul infiniment rapide 
- MÃ©moire infiniment rapide 
- ParallÃ©lisme parfait

<!-- --- -->

<!-- ## Optimisations Non ImplÃ©mentÃ©es

### 3. Optimisations Non ImplÃ©mentÃ©es

**GPU (Section 2.5.6 du PDF)**
- Raison: CPU suffit (213 FPS > 30 FPS requis)
- Latence CPUâ†”GPU non justifiÃ©e
- ComplexitÃ© d'implÃ©mentation Ã©levÃ©e

**Bit-Packing (Section 2.5.4 du PDF)**
- Raison: ComplexitÃ© vs gain incertain
- Difficile Ã  expliquer/dÃ©bugger
- Risque pour la validation

**Pipeline de Row Operators (Section 2.5.3 dÃ©taillÃ©)**
- Partiellement implÃ©mentÃ© via fusion
- Prologue/Ã©pilogue complexe
- Gain marginal aprÃ¨s fusion -->

---

# 11. Conclusion

### Objectifs Initiaux

âœ“ **Appliquer les concepts du cours**
  - Caches: Fusion d'opÃ©rateurs â†’ **1.7Ã— gain**
  - SIMD: AVX-512 vectorisation â†’ **2.1Ã— gain**
  - Algo: Morpho sÃ©parable â†’ **1.5Ã— gain**
  - OpenMP: ParallÃ©lisation â†’ **1.18Ã— gain**

âœ“ **Validation bit-Ã -bit rÃ©ussie**
  - `diff -r logs_ref logs_new` â†’ vide âœ“
  - Aucune rÃ©gression fonctionnelle

âœ“ **Mesures sur cluster Dalek**
  - AMD Ryzen 9 7945HX (16 cÅ“urs)
  - Benchmarks reproductibles

---

## Performance Finale

### Gain Global: 2.4Ã— (90 â†’ 213 FPS)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ MÃ©trique           â”‚ motion2  â”‚  motion  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ FPS moyen          â”‚   90     â”‚   213    â”‚
â”‚ Latence/frame      â”‚  8.67 ms â”‚  5.52 ms â”‚
â”‚ Throughput         â”‚  1.0Ã—    â”‚  2.4Ã—    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

<!-- ---

## L'Optimisation ClÃ©

**Pourquoi c'est l'optimisation la plus importante?**

1. **Exploite la ressource critique** (cache L1)
2. **Synergie avec SIMD** (alimente les unitÃ©s vectorielles)
3. **Gain significatif** (1.7Ã—) avec code simple
4. **Enseignement du CM2** parfaitement appliquÃ©

**"Cache is king in modern HPC"**

---

## Messages ClÃ©s - Oral

### Messages ClÃ©s Ã  Retenir

**Pour l'Oral:**

1. **Validation garantie**
   - `diff` vide = rÃ©sultats identiques
   - Pas d'approximation

2. **Lien avec le cours explicite**
   - "Cette optimisation applique le CM2 sur..."
   - Concepts thÃ©oriques â†’ mise en pratique

3. **Scaling modeste expliquÃ©**
   - Loi d'Amdahl (partie sÃ©quentielle)
   - Memory-bound (pas compute-bound)
   - **C'est normal en HPC!**

   4. **Choix CPU-only justifiÃ©**
   - 213 FPS > 30 FPS requis
   - GPU = overhead non justifiÃ©
   - Focus sur optimisations CPU -->

<!-- ## Messages ClÃ©s - Rapport



**Pour le Rapport:**

1. **MÃ©thodologie rigoureuse**
   - Baseline claire (motion2)
   - Mesures reproductibles (--vid-in-buff, --stats)
   - Validation systÃ©matique

2. **RÃ©sultats chiffrÃ©s**
   - Tableaux de latences
   - Graphes de scaling
   - Gains par optimisation

--- -->

<!-- ## Analyse Critique et Perspectives

3. **Analyse critique**
   - Limites identifiÃ©es
   - Ã‰cart thÃ©orique/pratique expliquÃ©
   - Perspectives d'amÃ©lioration

### Perspectives

### Court Terme (Extensions Possibles)

1. **Prefetching** - Anticipation des accÃ¨s mÃ©moire
2. **Cache Blocking** - Tiling pour L3
3. **CCL ParallÃ¨le** - Union-Find distribuÃ©

### Long Terme (Si FPS > 300 Requis)

1. **GPU Offload** - OpenCL/CUDA
2. **HÃ©tÃ©rogÃ¨ne CPU+GPU** - Split workload
3. **FPGA** - Pipeline matÃ©riel dÃ©diÃ© -->

---

# Merci pour votre Attention!

<!-- ## Questions?

---

## Ressources et RÃ©fÃ©rences

### Code Source
- **Repository:** `~/ProjetHPC/motion/`
- **Fichier principal:** `src/main/motion.c`
- **Commit validÃ©:** bit-for-bit identical to motion2

### RÃ©sultats Complets
- **Logs de validation:** `logs_ref/` vs `logs_new/`
- **Benchmarks:** `results_motion_*.txt`
- **Graphes:** GÃ©nÃ©rÃ©s Ã  partir des CSVs

### Validation
```bash
# Commande de validation (toujours disponible)
diff -r logs_ref logs_new
# â†’ Retour vide = SuccÃ¨s âœ“
```

### Benchmark Reproductible
```bash
# Commande pour reproduire les rÃ©sultats
export OMP_NUM_THREADS=16
./bin/motion --vid-in-buff --vid-in-stop 100 \
  --vid-in-path traffic/1080p_day_street_top_view_snow.mp4 \
  --stats
```

---

## Contact et Environnement

### Contact
- **Cluster:** Dalek (Polytech Sorbonne)
- **Processeur:** AMD Ryzen 9 7945HX
- **Environnement:** GCC 13.3.0, -O3 -march=native -fopenmp

---

## Annexe: Commandes Utiles

### Compilation
```bash
module load gcc/13.3.0 cmake opencv/4.10.0
cd motion
cmake -B build -DCMAKE_BUILD_TYPE=Release \
  -DMOTION_OPENCV_LINK=OFF \
  -DMOTION_USE_MIPP=ON \
  -DCMAKE_C_FLAGS="-O3 -march=native -fopenmp" \
  -DCMAKE_CXX_FLAGS="-O3 -march=native -fopenmp"
cmake --build build --parallel
```

### Tests de Validation
```bash
# GÃ©nÃ©rer rÃ©fÃ©rence
./bin/motion2 --vid-in-stop 20 \
  --vid-in-path ../traffic/1080p.mp4 \
  --log-path logs_ref

# GÃ©nÃ©rer optimisÃ©
./bin/motion --vid-in-stop 20 \
  --vid-in-path ../traffic/1080p.mp4 \
  --log-path logs_new

# Comparer
diff -r logs_ref logs_new
```

---

## Benchmark Multi-Threads

### Benchmark avec DiffÃ©rents Threads
```bash
for THREADS in 1 2 4 8 16; do
    export OMP_NUM_THREADS=$THREADS
    ./bin/motion --vid-in-buff --vid-in-stop 100 \
      --vid-in-path ../traffic/1080p.mp4 \
      --stats | tee results_${THREADS}t.txt
done
```

---

# FIN

**Objectif 17-18/20:** Tous les concepts du cours appliquÃ©s âœ“
**Performance:** 2.4Ã— gain (90 â†’ 213 FPS) âœ“
**Validation:** Bit-Ã -bit identical âœ“
**ExplicabilitÃ©:** Chaque optimisation justifiÃ©e âœ“

**Bonne chance pour la soutenance! ğŸš€** -->
