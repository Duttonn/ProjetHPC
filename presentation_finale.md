# Optimisation HPC - DÃ©tection de Mouvement
## Projet Motion - Du SÃ©quentiel au ParallÃ¨le

**Auteurs:** Nicolas Dutton, Antoine
**Cours:** High Performance Computing - EI5-SE
**Date:** Janvier 2026

---

# Plan de la PrÃ©sentation

1. **Architecture de Test**
2. **Contexte et Objectifs**
3. **Simplification Algorithmique (TP3)**
4. **Validation Bit-Ã -Bit**
5. **MÃ©thodologie de Benchmark**
6. **Vectorisation SIMD (CM3)**
7. **Fusion d'OpÃ©rateurs (CM2)**
8. **Morphologie SÃ©parable (CM3)**
9. **ParallÃ©lisation OpenMP (CM4)**
10. **RÃ©sultats Globaux**
11. **Discussion et Analyse**
12. **Conclusion**

---

# 1. Architecture de Test - Cluster Dalek

## Processeur: AMD Ryzen 9 7945HX

### SpÃ©cifications Techniques
- **CÅ“urs:** 16 cÅ“urs physiques / 32 threads logiques
- **FrÃ©quence:** 2.5 GHz base, jusqu'Ã  5.4 GHz boost
- **Architecture:** Zen 4 (5nm)
- **ISA:** x86-64 avec extensions AVX-512

---

## HiÃ©rarchie MÃ©moire

### HiÃ©rarchie MÃ©moire (Critical pour nos optimisations!)
- **Cache L1:** 32 KB instruction + 32 KB donnÃ©es par cÅ“ur
  - Latence: **0.5 ns** (~1-2 cycles)
- **Cache L2:** 1 MB par cÅ“ur
  - Latence: **7 ns** (~15 cycles)
- **Cache L3:** 64 MB partagÃ© entre tous les cÅ“urs
  - Latence: **40 ns** (~100 cycles)
- **RAM:** DDR5-4800 (38 GB/s bande passante)
  - Latence: **~100 ns** (~250 cycles)

### Pourquoi ces dÃ©tails sont importants?
**Ratio de latence L1 vs RAM: 200Ã—**
â†’ Garder les donnÃ©es en cache L1 = **gain Ã©norme!**

---

# 2. Contexte et Objectifs

## DÃ©tection de Mouvement par CamÃ©ra Fixe

### Pipeline de Traitement (3 Ã©tapes)
```
Grayscale Image
     â†“
[1. Sigma-Delta] â†’ DÃ©tection pixels en mouvement
     â†“ (Image binaire 0/1)
[2. Morphologie] â†’ Nettoyage (Opening + Closing)
     â†“ (Image binaire nettoyÃ©e)
[3. CCL + CCA] â†’ Identification des rÃ©gions (RoIs)
     â†“
   Tracking
```

### Contraintes du Projet
- âœ“ **CamÃ©ra fixe** (pas de recalage d'image)
- âœ“ **Temps rÃ©el** (objectif > 30 FPS)
- âœ“ **Validation bit-Ã -bit** (rÃ©sultats identiques Ã  motion2)
- âœ— **Pas de GPU** (focus CPU uniquement)

---

## Objectifs d'Optimisation

### Objectifs d'Optimisation
1. Appliquer les concepts du cours (CM2, CM3, CM4)
2. Maximiser le dÃ©bit (FPS)
3. Garantir la correction (validation)

---

# 3. Simplification Algorithmique (TP3)
## Section 2.1 du Poly - Task Graph Optimization

## ProblÃ¨me: Redondance des Calculs

### Graphe Initial (motion2)
```
Frame t-1:  I[t-1] â†’ Î£âˆ† â†’ Morpho â†’ CCL â†’ RoIs[t-1]
                                              â†“
Frame t:    I[t]   â†’ Î£âˆ† â†’ Morpho â†’ CCL â†’ RoIs[t]
                                              â†“
                                         [k-NN Matching]
```

**Observation Critique:**
Ã€ l'itÃ©ration t, on traite **I[t] ET I[t-1]**
Mais I[t-1] a dÃ©jÃ  Ã©tÃ© traitÃ© Ã  l'itÃ©ration t-1 !

---

## Solution: Produce/Memorize Pattern

### Solution: Produce/Memorize Pattern

```
Frame t:    I[t]   â†’ Î£âˆ† â†’ Morpho â†’ CCL â†’ RoIs[t]
                                         â†“ (mÃ©morisÃ©)
Frame t+1:  I[t+1] â†’ Î£âˆ† â†’ Morpho â†’ CCL â†’ RoIs[t+1]
                                         â†“
                    [k-NN Matching avec RoIs[t] mÃ©morisÃ©]
```

---

## Gain de la Simplification

### Pourquoi c'est Plus Rapide?

**Avant (motion2):**
- N frames â†’ 2N passages dans le pipeline (t et t-1)
- Travail: **2N**

**AprÃ¨s (motion):**
- N frames â†’ N passages dans le pipeline
- Travail: **N**

**Gain thÃ©orique: 2Ã— (division par 2 du travail)**

---

# 4. Validation Bit-Ã -Bit
## Section 2.2 du Poly - Garantie de Correction

## Processus de Validation

### Ã‰tape 1: GÃ©nÃ©ration des Logs de RÃ©fÃ©rence
```bash
./bin/motion2 --vid-in-stop 20 \
  --vid-in-path traffic/1080p.mp4 \
  --log-path logs_ref
```
â†’ GÃ©nÃ¨re logs_ref/ avec les RoIs frame par frame

### Ã‰tape 2: GÃ©nÃ©ration des Logs OptimisÃ©s
```bash
./bin/motion --vid-in-stop 20 \
  --vid-in-path traffic/1080p.mp4 \
  --log-path logs_new
```
â†’ GÃ©nÃ¨re logs_new/ avec les RoIs optimisÃ©s

---

## Comparaison et Garanties

### Ã‰tape 3: Comparaison Bit-Ã -Bit
```bash
diff -r logs_ref logs_new
```
**RÃ©sultat: AUCUNE DIFFÃ‰RENCE (vide) âœ“**

### Garanties ApportÃ©es

âœ“ **RÃ©sultats identiques** Ã  motion2
âœ“ **Aucune rÃ©gression fonctionnelle**
âœ“ **Optimisations purement techniques** (pas d'approximation)

**Message clÃ©:** "Nos optimisations accÃ©lÃ¨rent SANS changer les rÃ©sultats"

---

# 5. MÃ©thodologie de Benchmark
## Section 2.4 du Poly - Mesures de Performance

## Configuration des Tests

### ParamÃ¨tres de Benchmark
```bash
./bin/motion --vid-in-buff \
             --vid-in-stop 100 \
             --vid-in-path traffic/1080p_day_street_top_view_snow.mp4 \
             --stats
```

### Pourquoi ces ParamÃ¨tres?

**`--vid-in-buff`:**
- Buffer les 100 frames en mÃ©moire **avant** de mesurer
- Ã‰limine le coÃ»t du dÃ©codage vidÃ©o (hors scope)
- Simule une camÃ©ra rÃ©elle (pas de dÃ©codage)

**`--vid-in-stop 100`:**
- 100 frames = compromis temps/prÃ©cision
- Plus = plus prÃ©cis mais plus long

---

## MÃ©triques et Baseline

**`--stats`:**
- Affiche les latences par Ã©tape (Î£âˆ†, Morpho, CCL)
- Permet d'isoler l'impact de chaque optimisation

### MÃ©triques MesurÃ©es

1. **FPS moyen** (throughput global) - MÃ‰TRIQUE PRINCIPALE
2. **Latences par Ã©tape** (en ms) - Pour analyse dÃ©taillÃ©e
3. **Speedup** vs baseline (motion2)

### Baseline

**motion2 (rÃ©fÃ©rence):** 90 FPS, 8.67 ms/frame
â†’ Toutes les comparaisons se font vs cette baseline

---

# 6. Vectorisation SIMD (CM3)
## Section 2.5.1 du Poly - Registres Larges AVX-512

## Principe: Data-Level Parallelism

### ExÃ©cution Scalaire (1 pixel/cycle)
```
Cycle 1: |  P0  |
Cycle 2: |  P1  |
Cycle 3: |  P2  |
...
Cycle 32:|  P31 |
```
**Temps total: 32 cycles pour 32 pixels**

### ExÃ©cution SIMD AVX-512 (32 pixels/cycle)
```
Cycle 1: | P0 | P1 | P2 | ... | P31 |
```
**Temps total: 1 cycle pour 32 pixels**
**Gain thÃ©orique: 32Ã—**

---

## Code Scalaire vs SIMD

### Code Scalaire (Avant)
```c
for (int j = j0; j <= j1; j++) {
    uint8_t diff = abs(IG[i][j] - M[i][j]);
    uint8_t threshold = V[i][j];
    IB[i][j] = (diff > threshold) ? 255 : 0;
}
// 1920 pixels â†’ 1920 cycles minimum
```

---

## Code SIMD avec MIPP

### Code SIMD avec MIPP (AprÃ¨s)
```c
for (int j = j0; j <= j1; j += 32) {
    mipp::Reg<uint8_t> vIG = mipp::load<uint8_t>(&IG[i][j]);
    mipp::Reg<uint8_t> vM  = mipp::load<uint8_t>(&M[i][j]);
    mipp::Reg<uint8_t> vV  = mipp::load<uint8_t>(&V[i][j]);

    mipp::Reg<uint8_t> vDiff = mipp::abs(vIG - vM);
    mipp::Msk<uint8_t> mask = vDiff > vV;
    mipp::Reg<uint8_t> vIB = mipp::blend(255, 0, mask);

    mipp::store<uint8_t>(vIB, &IB[i][j]);
}
// 1920 pixels â†’ 60 cycles minimum (1920/32)
```

---

## Pourquoi SIMD est Plus Rapide?

### 1. ParallÃ©lisme de DonnÃ©es
- **32 pixels traitÃ©s en parallÃ¨le** dans un seul registre 512 bits
- MÃªme instruction appliquÃ©e Ã  32 donnÃ©es simultanÃ©ment

### 2. Moins d'Instructions ExÃ©cutÃ©es
- Scalaire: 1920 itÃ©rations de boucle
- SIMD: 60 itÃ©rations de boucle
- **RÃ©duction 32Ã— du nombre d'itÃ©rations**

### 3. Meilleure Utilisation du CPU
- UnitÃ©s de calcul SIMD dÃ©diÃ©es (saturÃ©es)
- Pipeline CPU rempli efficacement

---

## RÃ©sultats SIMD

### RÃ©sultats: Latence Sigma-Delta

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Version             â”‚ Latence (ms) â”‚ Speedup â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ motion2 (scalaire)  â”‚     1.20     â”‚  1.0Ã—   â”‚
â”‚ motion (SIMD AVX)   â”‚     0.569    â”‚  2.1Ã—   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Gain rÃ©el: 2.1Ã— (au lieu de 32Ã— thÃ©orique)**

### Pourquoi pas 32Ã—?
- Overhead load/store mÃ©moire
- Latence accÃ¨s RAM (mÃªme avec cache)
- DÃ©pendances de donnÃ©es

**Mais 2.1Ã— est un excellent gain pour une seule optimisation!**

---

# 7. Fusion d'OpÃ©rateurs (CM2)
## Section 2.5.3 du Poly - Cache Level Parallelism

## ProblÃ¨me: Cache Misses = Latence RAM

### Pipeline SÃ©quentiel (motion2)

```
Ã‰tape 1: Sigma-Delta
  IG (RAM) â”€â”€â†’ [CPU] â”€â”€â†’ IB (RAM Ã©criture)
                              â†“ (100ns latence!)
Ã‰tape 2: Morpho Opening
  IB (RAM lecture) â”€â”€â†’ [CPU] â”€â”€â†’ IB2 (RAM Ã©criture)
                                     â†“ (100ns latence!)
Ã‰tape 3: Morpho Closing
  IB2 (RAM lecture) â”€â”€â†’ [CPU] â”€â”€â†’ IB (RAM Ã©criture)
```

**CoÃ»t: 3 Ã©critures RAM + 2 lectures RAM = 5 Ã— 100ns = 500ns par pixel**

---

## HiÃ©rarchie MÃ©moire - Rappel

### HiÃ©rarchie MÃ©moire - Rappel

```
L1 Cache:  0.5ns   |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| Rapide!
L2 Cache:  7ns     |â–ˆâ–ˆâ–ˆ|
L3 Cache:  40ns    |
RAM:       100ns                                       | Lent!
```

**Ratio: RAM = 200Ã— plus lent que L1 !**

---

## Solution: Fusion en Une Seule Passe

### Solution: Fusion en Une Seule Passe

### Code FusionnÃ©
```c
sigma_delta_morpho_fused(sd_data, IG, IB, IB2, IB, i0, i1, j0, j1) {
    for (int i = i0; i <= i1; i++) {
        // Ligne i: Sigma-Delta calcule IB[i]
        sigma_delta_compute_line(IG[i], IB[i], ...);

        // IB[i] RESTE EN CACHE L1 (0.5ns) !

        // Ligne i: Morpho Opening utilise IB[i] directement
        morpho_opening_line(IB[i], IB2[i], ...);

        // IB2[i] RESTE EN CACHE L1 !

        // Ligne i: Morpho Closing utilise IB2[i] directement
        morpho_closing_line(IB2[i], IB[i], ...);
    }
    // Une seule Ã©criture finale IB â†’ RAM
}
```

### Flux de DonnÃ©es OptimisÃ©

```
IG (RAM) â”€â”€â†’ [Î£âˆ†] â”€â”€â†’ IB (L1 Cache 0.5ns)
                        â†“
                    [Opening] â”€â”€â†’ IB2 (L1 Cache 0.5ns)
                                   â†“
                               [Closing] â”€â”€â†’ IB (RAM Ã©criture)
```

**CoÃ»t: 1 lecture RAM + 1 Ã©criture RAM = 2 Ã— 100ns = 200ns par pixel**

---

## Pourquoi la Fusion AccÃ©lÃ¨re?

### 1. RÃ©duction des AccÃ¨s RAM
- **Avant:** 5 accÃ¨s RAM (3 Ã©critures + 2 lectures)
- **AprÃ¨s:** 2 accÃ¨s RAM (1 Ã©criture + 1 lecture)
- **Gain thÃ©orique RAM:** 2.5Ã—

### 2. LocalitÃ© Temporelle (CM2)
- DonnÃ©es utilisÃ©es **immÃ©diatement** aprÃ¨s production
- Restent dans cache L1 entre les Ã©tapes
- Pas d'Ã©viction du cache

---

## Avantages de la Fusion (suite)

### 3. RÃ©duction Latence Effective
- Latence RAM: 100ns
- Latence L1: 0.5ns
- **Ratio: 200Ã— plus rapide**

### 4. Combinaison avec SIMD
- Fusion + SIMD = double bÃ©nÃ©fice
- Cache L1 alimente les unitÃ©s SIMD Ã  pleine vitesse

---

## RÃ©sultats de la Fusion

### RÃ©sultats: Latence FusionnÃ©e

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Version          â”‚ Sigma-Delta â”‚ Morpho  â”‚ Total SD+Morpho  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ motion2 (sÃ©parÃ©) â”‚   1.20 ms   â”‚ 1.70 ms â”‚     2.90 ms      â”‚
â”‚ motion (fusionnÃ©)â”‚   0.569 ms  â”‚ 1.131ms â”‚     1.700 ms     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Gain: 1.7Ã— (2.9ms â†’ 1.7ms)**

**C'est l'optimisation la plus importante du projet!**

---

# 8. Morphologie SÃ©parable (CM3)
## Section 2.5.2 du Poly - RÃ©duction d'OpÃ©rations

## Principe: DÃ©composition MathÃ©matique

### Morphologie 3Ã—3 Standard (9 comparaisons/pixel)

```
Ã‰rosion 3Ã—3: min de 9 voisins
â”Œâ”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”
â”‚ 1 â”‚ 2 â”‚ 3 â”‚  â†’  result = min(1,2,3,4,5,6,7,8,9)
â”œâ”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¤
â”‚ 4 â”‚ X â”‚ 5 â”‚      9 comparaisons par pixel!
â”œâ”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¤
â”‚ 6 â”‚ 7 â”‚ 8 â”‚
â””â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”˜
```

**Image 1920Ã—1080: 1920 Ã— 1080 Ã— 9 = 18.6M comparaisons**

---

## Morphologie SÃ©parable (6 comparaisons/pixel)

### Morphologie SÃ©parable (6 comparaisons/pixel)

```
DÃ©composition: 3Ã—3 = (1Ã—3) âˆ˜ (3Ã—1)

Passe 1 - Horizontale 1Ã—3:
â”Œâ”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”
â”‚ A â”‚ X â”‚ B â”‚  â†’  temp = min(A, X, B)
â””â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”˜
                     3 comparaisons

Passe 2 - Verticale 3Ã—1:
â”Œâ”€â”€â”€â”
â”‚ C â”‚
â”œâ”€â”€â”€â”¤
â”‚tempâ”‚  â†’  result = min(C, temp, D)
â”œâ”€â”€â”€â”¤
â”‚ D â”‚
â””â”€â”€â”€â”˜
                     3 comparaisons
```

**Total: 6 comparaisons au lieu de 9**
**Image 1920Ã—1080: 1920 Ã— 1080 Ã— 6 = 12.4M comparaisons**

---

## Avantages de la SÃ©parabilitÃ©

### Pourquoi c'est Plus Rapide?

### 1. RÃ©duction du Nombre d'OpÃ©rations
- **9 ops â†’ 6 ops = rÃ©duction 33%**
- Moins de calculs = moins de temps CPU

### 2. Vectorisation Optimale (Passe Horizontale)
```c
// Passe horizontale: accÃ¨s mÃ©moire contigus
for (int j = j0; j <= j1; j += 32) {
    // 32 pixels consÃ©cutifs â†’ parfait pour SIMD!
    mipp::Reg<uint8_t> vLeft   = load(&img[i][j-1]);
    mipp::Reg<uint8_t> vCenter = load(&img[i][j]);
    mipp::Reg<uint8_t> vRight  = load(&img[i][j+1]);

    mipp::Reg<uint8_t> vMin = mipp::min(vLeft, vCenter, vRight);
    store(vMin, &temp[i][j]);
}
```

**AccÃ¨s contigus = cache-friendly + SIMD-friendly**

### 3. LocalitÃ© Spatiale (CM2)
- Passe horizontale: mÃªme ligne en cache
- Passe verticale: lignes adjacentes (cache L2)
- Moins de cache misses

---

## RÃ©sultats Morphologie SÃ©parable

### RÃ©sultats: Latence Morphologie

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Version              â”‚ Ops/pixel        â”‚ Latence (ms) â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ motion2 (3Ã—3 direct) â”‚        9         â”‚     1.70     â”‚
â”‚ motion (sÃ©parable)   â”‚        6         â”‚     1.131    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Gain: 1.5Ã— (1.7ms â†’ 1.13ms)**

### Bonus: Combinaison avec Fusion
- Morpho sÃ©parable + Fusion d'opÃ©rateurs
- Passes horizontales restent en cache L1
- **Synergie des optimisations!**

---

# 9. ParallÃ©lisation OpenMP (CM4)
## Section 2.5.1 du Poly - Thread-Level Parallelism

## Principe: DÃ©composition de Domaine

### Architecture: 16 CÅ“urs Physiques

```
â”Œâ”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”
â”‚Core0â”‚Core1â”‚Core2â”‚Core3â”‚Core4â”‚Core5â”‚Core6â”‚Core7â”‚
â””â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”˜
â”Œâ”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”
â”‚Core8â”‚Core9â”‚Cor10â”‚Cor11â”‚Cor12â”‚Cor13â”‚Cor14â”‚Cor15â”‚
â””â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”˜
            Ryzen 9 7945HX (16 cÅ“urs)
```

**IdÃ©e:** Distribuer le traitement sur les 16 cÅ“urs

---

## ImplÃ©mentation OpenMP

### ImplÃ©mentation: OpenMP Parallel For

```c
#pragma omp parallel for schedule(static)
for (int i = i0; i <= i1; i++) {
    // Chaque thread traite un sous-ensemble de lignes
    sigma_delta_morpho_fused(..., i, i, ...);
}
```

**Avec 16 threads â†’ chaque thread traite 1080/16 = 67 lignes**

---

## StratÃ©gie de Scheduling

### StratÃ©gie de Scheduling

### `schedule(static)` - Pourquoi?

```
Image 1080 lignes, 16 threads:

Thread 0:  lignes 0-67    â”
Thread 1:  lignes 68-135  â”‚ Chunks contigus
Thread 2:  lignes 136-203 â”‚ â†’ Cache locality
...                        â”‚
Thread 15: lignes 1013-1080â”˜
```

**Avantage:** Chaque thread traite des **lignes consÃ©cutives**
- Cache L2 partagÃ© entre threads proches
- Moins de cache conflicts
- PrÃ©dictibilitÃ© (pas de vol de travail)

---

## Pourquoi OpenMP AccÃ©lÃ¨re?

### 1. Exploitation du ParallÃ©lisme MatÃ©riel
- 16 cÅ“urs disponibles
- **1 thread par cÅ“ur** (pas d'hyperthreading ici)
- Calculs indÃ©pendants (lignes sÃ©parÃ©es)

### 2. ScalabilitÃ© IdÃ©ale (ThÃ©orique)
- **1 thread:** T secondes
- **16 threads:** T/16 secondes (idÃ©al)
- **Speedup idÃ©al:** 16Ã—

---

## LocalitÃ© de Cache

### 3. LocalitÃ© de Cache (CM2 + CM4)
- `schedule(static)`: chunks contigus
- Thread N traite toujours les mÃªmes lignes
- Cache L1/L2 du cÅ“ur reste chaud

---

## RÃ©sultats OpenMP Scaling

### RÃ©sultats: Scaling OpenMP

### Graphe 1: FPS vs Nombre de Threads

![OpenMP Scaling - FPS](graph_openmp_scaling_fps.png)

### Graphe 2: Speedup vs Nombre de Threads

![OpenMP Scaling - Speedup](graph_openmp_speedup.png)

### Tableau DÃ©taillÃ©

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Threads â”‚ Avg FPS â”‚ Speedup vs 1t    â”‚ EfficacitÃ© â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚    1    â”‚   181   â”‚      1.00Ã—       â”‚   100%     â”‚
â”‚    2    â”‚   172   â”‚      0.95Ã—       â”‚    48%     â”‚
â”‚    4    â”‚   189   â”‚      1.04Ã—       â”‚    26%     â”‚
â”‚    8    â”‚   206   â”‚      1.14Ã—       â”‚    14%     â”‚
â”‚   16    â”‚   213   â”‚      1.18Ã—       â”‚     7%     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Gain rÃ©el: 1.18Ã— avec 16 threads (au lieu de 16Ã— idÃ©al)**

---

## Pourquoi Scaling Modeste?

### 1. Loi d'Amdahl (CM4)

```
Speedup = 1 / ((1-P) + P/N)

Avec:
- P = fraction parallÃ©lisable
- N = nombre de threads
- (1-P) = fraction sÃ©quentielle
```

**Notre cas:**
- DÃ©codage vidÃ©o: sÃ©quentiel (buffered mais coÃ»teux)
- CCL: difficilement parallÃ©lisable (union-find)
- k-NN matching: sÃ©quentiel
- **Partie parallÃ©lisable estimÃ©e: P â‰ˆ 60%**

**Speedup max thÃ©orique: 1/(0.4) = 2.5Ã—**

---

## Limites du ParallÃ©lisme

### 2. Memory Bandwidth Bottleneck

```
16 cÅ“urs Ã— 38 GB/s RAM / 16 = 2.4 GB/s par cÅ“ur

Image 1920Ã—1080Ã—3 (RGB) = 6.2 MB
100 FPS â†’ 620 MB/s par cÅ“ur nÃ©cessaire

Avec 16 threads:
16 Ã— 620 MB/s = 9.9 GB/s < 38 GB/s (OK)

MAIS: AccÃ¨s non parfaits (cache misses, false sharing, ...)
â†’ Saturation partielle de la bande passante
```

### 3. Overhead OpenMP
- CrÃ©ation/synchronisation threads: ~1-2 Âµs
- BarriÃ¨res implicites (fin de parallel for)
- Cache coherency protocol (MESI)

### 4. Workload Memory-Bound (pas Compute-Bound)
- CPU attend la RAM plus qu'il ne calcule
- Ajouter plus de threads ne rÃ©sout pas le problÃ¨me RAM

---

## Conclusion OpenMP

### Conclusion OpenMP

**Scaling modeste (1.18Ã—) mais:**
- âœ“ Scaling **positif** (pas de dÃ©gradation)
- âœ“ Gain **gratuit** (juste une directive)
- âœ“ CombinÃ© avec SIMD+Fusion = **2.4Ã— total**

**C'est normal en HPC!** Memory-bound workloads ne scalent jamais linÃ©airement.

---

# 10. RÃ©sultats Globaux
## SynthÃ¨se de Toutes les Optimisations

## Graphe 1: Performance FPS par Configuration

![Comparaison FPS - Toutes Configurations](graph_fps_comparison.png)

**Gain final: 2.4Ã— (90 â†’ 213 FPS)**

---

## Tableau Performances FPS

### Tableau Performances FPS

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Configuration           â”‚ Avg FPS â”‚ Speedup â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ motion2 (rÃ©fÃ©rence)     â”‚   ~90   â”‚  1.0Ã—   â”‚
â”‚ motion (1 thread)       â”‚   181   â”‚  2.0Ã—   â”‚
â”‚ motion (2 threads)      â”‚   172   â”‚  1.9Ã—   â”‚
â”‚ motion (4 threads)      â”‚   189   â”‚  2.1Ã—   â”‚
â”‚ motion (8 threads)      â”‚   206   â”‚  2.3Ã—   â”‚
â”‚ motion (16 threads)     â”‚   213   â”‚  2.4Ã—   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## DÃ©composition des Latences

### Graphe 2: DÃ©composition des Gains par Ã‰tape

### Comparaison Latences par Ã‰tape

![Latences par Ã‰tape - motion2 vs motion](graph_latencies_comparison.png)

### Latences EmpilÃ©es (Breakdown Total)

![Latences EmpilÃ©es - DÃ©composition](graph_latency_stacked.png)

**Comparaison:**
- motion2: 1.20ms (Î£âˆ†) + 1.70ms (Morpho) + 4.30ms (CCL) = 8.67ms total
- motion: 0.569ms (Î£âˆ†) + 1.131ms (Morpho) + 2.340ms (CCL) = 5.516ms total

---

## Tableau Latences DÃ©taillÃ©es

### Tableau Latences DÃ©taillÃ©es

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Ã‰tape            â”‚ motion2 â”‚ motion (optimisÃ©)â”‚ Speedup â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Video decoding   â”‚ 0.17 ms â”‚     0.166 ms     â”‚  1.0Ã—   â”‚
â”‚ Sigma-Delta      â”‚ 1.20 ms â”‚     0.569 ms     â”‚  2.1Ã—   â”‚ â† SIMD
â”‚ Morphology       â”‚ 1.70 ms â”‚     1.131 ms     â”‚  1.5Ã—   â”‚ â† SÃ©parable+SIMD
â”‚ CC Labeling      â”‚ 4.30 ms â”‚     2.340 ms     â”‚  1.8Ã—   â”‚
â”‚ CC Analysis      â”‚ 1.30 ms â”‚     1.300 ms     â”‚  1.0Ã—   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ TOTAL            â”‚ 8.67 ms â”‚     5.516 ms     â”‚  1.6Ã—   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Contribution de Chaque Optimisation

### DÃ©composition des Gains

### Contribution de Chaque Optimisation

```
Baseline (motion2):                90 FPS (1.0Ã—)
    â†“
+ Task Graph (TP3):               ~180 FPS (2.0Ã—)
    â†“
+ SIMD (CM3):                     IntÃ©grÃ© dans fusion
    â†“
+ Fusion + SÃ©parable (CM2+CM3):   ~181 FPS (effet sur latence)
    â†“
+ OpenMP 16 threads (CM4):         213 FPS (2.4Ã—)
```

---

## Points Forts par Optimisation

### Points Forts par Optimisation

1. **Task Graph (TP3):** Gain 2Ã— immÃ©diat
   - SimplicitÃ© d'implÃ©mentation
   - Pas de compromis

2. **SIMD (CM3):** Gain 2.1Ã— sur Sigma-Delta
   - Exploite l'architecture moderne
   - Transparence (MIPP)

3. **Fusion d'OpÃ©rateurs (CM2):** Gain 1.7Ã— combinÃ©
   - **Optimisation clÃ©** (cache locality)
   - Synergie avec SIMD

---

## Points Forts (suite)

4. **Morpho SÃ©parable (CM3):** Gain 1.5Ã—
   - RÃ©duction algorithmique
   - Vectorisation optimale

5. **OpenMP (CM4):** Gain 1.18Ã—
   - Modeste mais positif
   - Gratuit (une directive)

---

# 11. Discussion et Analyse
## Retour d'ExpÃ©rience et LeÃ§ons Apprises

## SuccÃ¨s des Optimisations

### RÃ©capitulatif des Gains MesurÃ©s

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Optimisation           â”‚ Coursâ”‚ Gain                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Task Graph             â”‚ TP3  â”‚ 2.0Ã— (FPS)          â”‚
â”‚ SIMD AVX-512           â”‚ CM3  â”‚ 2.1Ã— (Sigma-Delta)  â”‚
â”‚ Fusion d'OpÃ©rateurs    â”‚ CM2  â”‚ 1.7Ã— (SD+Morpho)    â”‚
â”‚ Morpho SÃ©parable       â”‚ CM3  â”‚ 1.5Ã— (Morpho)       â”‚
â”‚ OpenMP 16 threads      â”‚ CM4  â”‚ 1.18Ã— (global)      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ TOTAL COMBINÃ‰          â”‚      â”‚ 2.4Ã— (90â†’213 FPS)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Ce qui a Bien MarchÃ©

âœ“ **Fusion d'OpÃ©rateurs (CM2)** - L'optimisation MVP
  - Exploite la hiÃ©rarchie mÃ©moire
  - Cache L1: 200Ã— plus rapide que RAM
  - Combinaison naturelle avec SIMD

âœ“ **SIMD (CM3)** - Gain significatif
  - AVX-512: 32 pixels/cycle
  - BibliothÃ¨que MIPP: portabilitÃ©
  - Code lisible et maintenable

âœ“ **Task Graph (TP3)** - Low-hanging fruit
  - Gain immÃ©diat sans complexitÃ©
  - Correctness proof simple

---

## Limites RencontrÃ©es

### Limites RencontrÃ©es

### 1. Scaling OpenMP Modeste (1.18Ã—)

**Causes IdentifiÃ©es:**

**A) Loi d'Amdahl**
```
Speedup_max = 1 / (S + P/N)
Avec S = 0.4 (40% sÃ©quentiel)
     P = 0.6 (60% parallÃ¨le)
     N = 16 threads

Speedup_max = 1 / (0.4 + 0.6/16) = 2.46Ã—
Speedup_rÃ©el = 1.18Ã—
```
**EfficacitÃ©: 48% du maximum thÃ©orique**

---

## Causes du Scaling Modeste

**B) Memory Bandwidth Bottleneck**
- 16 cÅ“urs accÃ¨dent simultanÃ©ment Ã  la RAM
- Contention sur le bus mÃ©moire
- Saturation partielle de la bande passante

**C) CCL Difficile Ã  ParallÃ©liser**
- Union-Find: dÃ©pendances globales
- Synchronisation requise
- Reste sÃ©quentiel dans notre implÃ©mentation

---

## Ã‰cart ThÃ©orique/Pratique

### 2. Ã‰cart ThÃ©orique/Pratique

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Optimisationâ”‚ ThÃ©orique â”‚   RÃ©el     â”‚ Ratio     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ SIMD        â”‚    32Ã—    â”‚    2.1Ã—    â”‚   6.5%    â”‚
â”‚ OpenMP      â”‚    16Ã—    â”‚    1.18Ã—   â”‚   7.4%    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Pourquoi cet Ã©cart?**
- **Latence mÃ©moire** (goulot d'Ã©tranglement)
- **Overhead** (load/store, synchronisation)
- **Partie sÃ©quentielle** (Amdahl)

**C'est normal!** Les gains thÃ©oriques supposent:
- Calcul infiniment rapide (pas vrai)
- MÃ©moire infiniment rapide (pas vrai)
- ParallÃ©lisme parfait (pas vrai)

---

## Optimisations Non ImplÃ©mentÃ©es

### 3. Optimisations Non ImplÃ©mentÃ©es

**GPU (Section 2.5.6 du PDF)**
- Raison: CPU suffit (213 FPS > 30 FPS requis)
- Latence CPUâ†”GPU non justifiÃ©e
- ComplexitÃ© d'implÃ©mentation Ã©levÃ©e

**Bit-Packing (Section 2.5.4 du PDF)**
- Raison: ComplexitÃ© vs gain incertain
- Difficile Ã  expliquer/dÃ©bugger
- Risque pour la validation

**Pipeline de Row Operators (Section 2.5.3 dÃ©taillÃ©)**
- Partiellement implÃ©mentÃ© via fusion
- Prologue/Ã©pilogue complexe
- Gain marginal aprÃ¨s fusion

---

## LeÃ§ons Apprises

### LeÃ§ons Apprises

### 1. La HiÃ©rarchie MÃ©moire est Critique (CM2)
**Enseignement principal du projet**

```
Optimisation de cache > Optimisation de calcul

Cache L1 (0.5ns) vs RAM (100ns) = 200Ã— diffÃ©rence
â†’ Garder les donnÃ©es en L1 = PRIORITÃ‰ #1
```

---

## LeÃ§ons Apprises (suite)

### 2. Combiner les Optimisations = Synergie

**Fusion + SIMD + OpenMP:**
- Fusion: garde donnÃ©es en cache
- SIMD: traite 32 pixels en parallÃ¨le
- OpenMP: distribue sur 16 cÅ“urs
- **Effet multiplicatif!**

### 3. Profiler Avant d'Optimiser

**Utilisation de `--stats`:**
- Identification des hotspots (CCL = 50% du temps)
- Mesure de l'impact de chaque optim
- **"Measure, don't guess"**

---

## LeÃ§ons Apprises (suite 2)

### 4. Validation = Non-NÃ©gociable

```bash
diff -r logs_ref logs_new  # MUST be empty!
```
- SÃ©curitÃ© contre les rÃ©gressions
- Confiance dans les optimisations
- Requis pour la production

### 5. Memory-Bound â‰  Compute-Bound

**Notre workload:**
- OpÃ©rations simples (comparaisons, min/max)
- Beaucoup de donnÃ©es (1920Ã—1080 pixels)
- **LimitÃ© par la RAM, pas le CPU**

**ConsÃ©quence:**
- Ajouter des cÅ“urs aide peu
- Optimiser les accÃ¨s mÃ©moire aide beaucoup

---

## Perspectives d'AmÃ©lioration

### Perspectives d'AmÃ©lioration

### 1. Prefetching Explicite
```c
__builtin_prefetch(&IG[i+8][j], 0, 3);  // Anticipate next lines
```
**Gain estimÃ©:** +5-10%

### 2. Cache Blocking (Tiling)
```c
// Process 64Ã—64 tiles to fit in L3 cache
for (tile_i...) for (tile_j...)
    process_tile(tile_i, tile_j);
```
**Gain estimÃ©:** +10-20%

### 3. ParallÃ©lisation CCL
- Light-weight Union-Find distribuÃ©
- Merge de labels en fin
**Gain estimÃ©:** +20-30%

### 4. GPU (si nÃ©cessaire)
- Seulement si FPS requis > 300
- OpenCL ou CUDA
**Gain estimÃ©:** 5-10Ã— (mais +latence)

---

# 12. Conclusion
## SynthÃ¨se et Objectifs Atteints

## RÃ©capitulatif des Objectifs

### Objectifs Initiaux (Slide 2)

âœ“ **Appliquer les concepts du cours (CM2, CM3, CM4)**
  - CM2 (Caches): Fusion d'opÃ©rateurs â†’ **1.7Ã— gain**
  - CM3 (SIMD): AVX-512 vectorisation â†’ **2.1Ã— gain**
  - CM3 (Algo): Morpho sÃ©parable â†’ **1.5Ã— gain**
  - CM4 (OpenMP): ParallÃ©lisation â†’ **1.18Ã— gain**

âœ“ **Optimiser sans GPU (focus CPU)**
  - 213 FPS > 30 FPS requis (7Ã— la cible)
  - GPU non nÃ©cessaire

âœ“ **Validation bit-Ã -bit rÃ©ussie**
  - `diff -r logs_ref logs_new` â†’ vide âœ“
  - Aucune rÃ©gression fonctionnelle

âœ“ **Mesures sur cluster Dalek**
  - AMD Ryzen 9 7945HX (16 cÅ“urs)
  - Benchmarks reproductibles

---

## Performance Finale

### Performance Finale

### Gain Global: 2.4Ã— (90 â†’ 213 FPS)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ MÃ©trique           â”‚ motion2  â”‚  motion  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ FPS moyen          â”‚   90     â”‚   213    â”‚
â”‚ Latence/frame      â”‚  8.67 ms â”‚  5.52 ms â”‚
â”‚ Throughput         â”‚  1.0Ã—    â”‚  2.4Ã—    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### DÃ©composition du Gain 2.4Ã—

```
1.0Ã— (motion2 baseline)
  Ã— 2.0 (Task Graph TP3)
  Ã— 1.2 (SIMD+Fusion+SÃ©parable CM2+CM3)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
= 2.4Ã— (motion optimisÃ© 16 threads)
```

---

## Trois Piliers du HPC

### Trois Piliers du HPC AppliquÃ©s

**1. EfficacitÃ© Algorithmique (TP3)**
- Task Graph: diviser le travail par 2
- Morpho sÃ©parable: 9 ops â†’ 6 ops

**2. Exploitation de l'Architecture (CM2, CM3)**
- SIMD: 32 pixels/cycle (AVX-512)
- Cache: L1 200Ã— plus rapide que RAM
- Fusion: garder donnÃ©es en cache chaud

**3. ParallÃ©lisme Multi-CÅ“urs (CM4)**
- OpenMP: 16 cÅ“urs exploitÃ©s
- Scaling limitÃ© par Amdahl et mÃ©moire
- Mais gain positif (1.18Ã—)

---

## L'Optimisation ClÃ©: Fusion (CM2)

### L'Optimisation ClÃ©: Fusion (CM2)

**Pourquoi c'est l'optimisation la plus importante?**

1. **Exploite la ressource critique** (cache L1)
2. **Synergie avec SIMD** (alimente les unitÃ©s vectorielles)
3. **Gain significatif** (1.7Ã—) avec code simple
4. **Enseignement du CM2** parfaitement appliquÃ©

**"Cache is king in modern HPC"**

---

## Messages ClÃ©s - Oral

### Messages ClÃ©s Ã  Retenir

**Pour l'Oral:**

1. **Validation garantie**
   - `diff` vide = rÃ©sultats identiques
   - Pas d'approximation

2. **Lien avec le cours explicite**
   - "Cette optimisation applique le CM2 sur..."
   - Concepts thÃ©oriques â†’ mise en pratique

3. **Scaling modeste expliquÃ©**
   - Loi d'Amdahl (partie sÃ©quentielle)
   - Memory-bound (pas compute-bound)
   - **C'est normal en HPC!**

---

## Messages ClÃ©s - Rapport

4. **Choix CPU-only justifiÃ©**
   - 213 FPS > 30 FPS requis
   - GPU = overhead non justifiÃ©
   - Focus sur optimisations CPU

**Pour le Rapport:**

1. **MÃ©thodologie rigoureuse**
   - Baseline claire (motion2)
   - Mesures reproductibles (--vid-in-buff, --stats)
   - Validation systÃ©matique

2. **RÃ©sultats chiffrÃ©s**
   - Tableaux de latences
   - Graphes de scaling
   - Gains par optimisation

---

## Analyse Critique et Perspectives

3. **Analyse critique**
   - Limites identifiÃ©es
   - Ã‰cart thÃ©orique/pratique expliquÃ©
   - Perspectives d'amÃ©lioration

### Perspectives

### Court Terme (Extensions Possibles)

1. **Prefetching** - Anticipation des accÃ¨s mÃ©moire
2. **Cache Blocking** - Tiling pour L3
3. **CCL ParallÃ¨le** - Union-Find distribuÃ©

### Long Terme (Si FPS > 300 Requis)

1. **GPU Offload** - OpenCL/CUDA
2. **HÃ©tÃ©rogÃ¨ne CPU+GPU** - Split workload
3. **FPGA** - Pipeline matÃ©riel dÃ©diÃ©

---

# Merci pour votre Attention!

## Questions?

---

## Ressources et RÃ©fÃ©rences

### Code Source
- **Repository:** `~/ProjetHPC/motion/`
- **Fichier principal:** `src/main/motion.c`
- **Commit validÃ©:** bit-for-bit identical to motion2

### RÃ©sultats Complets
- **Logs de validation:** `logs_ref/` vs `logs_new/`
- **Benchmarks:** `results_motion_*.txt`
- **Graphes:** GÃ©nÃ©rÃ©s Ã  partir des CSVs

### Validation
```bash
# Commande de validation (toujours disponible)
diff -r logs_ref logs_new
# â†’ Retour vide = SuccÃ¨s âœ“
```

### Benchmark Reproductible
```bash
# Commande pour reproduire les rÃ©sultats
export OMP_NUM_THREADS=16
./bin/motion --vid-in-buff --vid-in-stop 100 \
  --vid-in-path traffic/1080p_day_street_top_view_snow.mp4 \
  --stats
```

---

## Contact et Environnement

### Contact
- **Cluster:** Dalek (Polytech Sorbonne)
- **Processeur:** AMD Ryzen 9 7945HX
- **Environnement:** GCC 13.3.0, -O3 -march=native -fopenmp

---

## Annexe: Commandes Utiles

### Compilation
```bash
module load gcc/13.3.0 cmake opencv/4.10.0
cd motion
cmake -B build -DCMAKE_BUILD_TYPE=Release \
  -DMOTION_OPENCV_LINK=OFF \
  -DMOTION_USE_MIPP=ON \
  -DCMAKE_C_FLAGS="-O3 -march=native -fopenmp" \
  -DCMAKE_CXX_FLAGS="-O3 -march=native -fopenmp"
cmake --build build --parallel
```

### Tests de Validation
```bash
# GÃ©nÃ©rer rÃ©fÃ©rence
./bin/motion2 --vid-in-stop 20 \
  --vid-in-path ../traffic/1080p.mp4 \
  --log-path logs_ref

# GÃ©nÃ©rer optimisÃ©
./bin/motion --vid-in-stop 20 \
  --vid-in-path ../traffic/1080p.mp4 \
  --log-path logs_new

# Comparer
diff -r logs_ref logs_new
```

---

## Benchmark Multi-Threads

### Benchmark avec DiffÃ©rents Threads
```bash
for THREADS in 1 2 4 8 16; do
    export OMP_NUM_THREADS=$THREADS
    ./bin/motion --vid-in-buff --vid-in-stop 100 \
      --vid-in-path ../traffic/1080p.mp4 \
      --stats | tee results_${THREADS}t.txt
done
```

---

# FIN

**Objectif 17-18/20:** Tous les concepts du cours appliquÃ©s âœ“
**Performance:** 2.4Ã— gain (90 â†’ 213 FPS) âœ“
**Validation:** Bit-Ã -bit identical âœ“
**ExplicabilitÃ©:** Chaque optimisation justifiÃ©e âœ“

**Bonne chance pour la soutenance! ğŸš€**
